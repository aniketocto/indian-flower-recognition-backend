# ğŸŒ¸ Flower Recognition System (AI + Grad-CAM)

An end-to-end **flower image recognition system** built using **PyTorch**, **FastAPI**, and a lightweight **HTML/CSS/JavaScript frontend**. The project focuses on **learning-first ML engineering**, GPU utilization, explainable AI (Grad-CAM), and clean deployment architecture.

---

## ğŸ“Œ Project Overview

This project is an end-to-end **flower image recognition system** built using **PyTorch**, **FastAPI**, and a lightweight **HTML/CSS/JavaScript frontend**.

The current version of the system supports classification of **37 curated flower classes**, providing:
- Predicted flower name
- Scientific name
- Prediction confidence
- Explainable AI visualization using Grad-CAM

The architecture is designed to be modular and scalable, allowing additional flower classes to be added in future iterations.

The system is split into:

* **Frontend** (static, cloud-deployable)
* **Backend** (FastAPI + PyTorch, local GPU-powered)

---

## ğŸ¯ Objectives

* Build a complete ML pipeline from scratch
* Learn GPU-based training & inference
* Implement explainable AI using Grad-CAM
* Create a clean, interactive frontend
* Deploy using a realistic, industry-style architecture

---

## ğŸ“¦ Model & Dataset Files

Due to size constraints, trained model weights and datasets are not included in this repository.

- Model files (.pth) can be generated by running the training scripts
- Datasets should be placed inside the `data/` directory

This approach keeps the repository lightweight and reproducible.

---

## ğŸ–¥ï¸ System Requirements

| Component | Details                    |
| --------- | -------------------------- |
| OS        | Windows 10 / 11            |
| GPU       | NVIDIA RTX 2050 (4GB VRAM) |
| CUDA      | 11.8                       |
| Python    | 3.10                       |
| Framework | PyTorch (CUDA-enabled)     |

---

## ğŸ§± Tech Stack

### Backend

* Python
* PyTorch
* FastAPI
* Uvicorn
* Grad-CAM

### Frontend

* HTML
* CSS (custom doodle / botanical styles)
* Vanilla JavaScript

### Deployment

* Frontend: Vercel (static hosting)
* Backend: Local machine (GPU-powered)

---

## ğŸ“ Project Structure

```text
ml-gpu-project/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/           # API routes
â”‚   â”œâ”€â”€ core/          # Model loading & config
â”‚   â”œâ”€â”€ models/        # Trained model files (.pth)
â”‚   â”œâ”€â”€ outputs/       # Grad-CAM outputs
â”‚   â”œâ”€â”€ utils/         # Helper functions
â”‚   â””â”€â”€ main.py        # FastAPI entry point
â”‚
â”œâ”€â”€ data/              # Datasets
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ venv/              # Python virtual environment
â””â”€â”€ README.md
```

---

## ğŸ§ª Project Phases & Progress

### âœ… Phase 1: GPU & CUDA Setup

* Installed NVIDIA drivers
* Installed CUDA Toolkit 11.8
* Verified using `nvidia-smi` and `nvcc --version`

### âœ… Phase 2: Python Environment Setup

* Python 3.10 installed
* Virtual environment created and activated

### âœ… Phase 3: PyTorch GPU Installation

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

Verified GPU usage inside PyTorch.

### âœ… Phase 4: Dataset Setup

* Dataset: **Oxford Flowers 102**
* Images: ~8,189
* Size: ~350 MB
* Labels validated

### âœ… Phase 5: Model Training

* Transfer learning using **MobileNetV2**
* Backbone frozen, classifier trained
* GPU-accelerated training
* Final validation accuracy: ~92%

### âœ… Phase 6: Inference & Explainability

* Single-image inference implemented
* Grad-CAM heatmaps generated
* Images saved for frontend use

### âœ… Phase 7: Frontend Integration

* Image upload & preview
* Scanning animation during inference
* Result rendering with confidence scores

---

## ğŸš€ Running the Project Locally

### 1ï¸âƒ£ Activate Virtual Environment

```bash
cd ml-gpu-project
venv\Scripts\activate
```

### 2ï¸âƒ£ Start Backend (FastAPI)

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Check:

* API Docs: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
* Health: [http://127.0.0.1:8000/health](http://127.0.0.1:8000/health)

### 3ï¸âƒ£ Run Frontend

```bash
cd frontend
python -m http.server 5500
```

Open:

```
http://127.0.0.1:5500
```

---

## ğŸŒ Deployment Strategy (PATH A)

### Frontend

* Hosted on **Vercel** (static hosting)

### Backend

* Runs locally on GPU machine
* Frontend communicates via REST API using local IP

This approach:

* Avoids cloud GPU costs
* Is perfect for demos, viva, and learning
* Follows real-world frontend/backend separation

---

## ğŸ§  Key Learnings

* GPU compatibility is critical before ML work
* Grad-CAM greatly improves model trust
* ML projects benefit massively from good documentation
* Separating frontend & backend simplifies deployment

---

## ğŸ“Œ Future Improvements

* Cloud GPU deployment (AWS / GCP)
* Dockerization of backend
* Authentication & rate limiting
* Advanced Grad-CAM visualizations
* Mobile-friendly UI

---

## ğŸ‘¤ Author

**Aniket**
Student | Full-Stack & ML Enthusiast

---

## ğŸ“œ License

This project is for educational and research purposes.


